{
    "name": "root",
    "gauges": {
        "WallPlacer.Policy.Entropy.mean": {
            "value": 1.6450068950653076,
            "min": 1.6206295490264893,
            "max": 2.0857884883880615,
            "count": 81
        },
        "WallPlacer.Policy.Entropy.sum": {
            "value": 32.90013885498047,
            "min": 21.93701171875,
            "max": 41.71577072143555,
            "count": 81
        },
        "WallPlacer.Environment.EpisodeLength.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 81
        },
        "WallPlacer.Environment.EpisodeLength.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 81
        },
        "WallPlacer.Step.mean": {
            "value": 5739.0,
            "min": 4139.0,
            "max": 5739.0,
            "count": 81
        },
        "WallPlacer.Step.sum": {
            "value": 5739.0,
            "min": 4139.0,
            "max": 5739.0,
            "count": 81
        },
        "WallPlacer.Policy.ExtrinsicValueEstimate.mean": {
            "value": -590.9484252929688,
            "min": -1650.546142578125,
            "max": -523.200439453125,
            "count": 81
        },
        "WallPlacer.Policy.ExtrinsicValueEstimate.sum": {
            "value": -11818.96875,
            "min": -33010.921875,
            "max": -10464.0087890625,
            "count": 81
        },
        "WallPlacer.Environment.CumulativeReward.mean": {
            "value": -854.2254653930664,
            "min": -854.2254653930664,
            "max": -1.221027910709381,
            "count": 81
        },
        "WallPlacer.Environment.CumulativeReward.sum": {
            "value": -17084.509307861328,
            "min": -17084.509307861328,
            "max": -12.210279107093811,
            "count": 81
        },
        "WallPlacer.Policy.ExtrinsicReward.mean": {
            "value": -854.2254653930664,
            "min": -854.2254653930664,
            "max": -1.221027910709381,
            "count": 81
        },
        "WallPlacer.Policy.ExtrinsicReward.sum": {
            "value": -17084.509307861328,
            "min": -17084.509307861328,
            "max": -12.210279107093811,
            "count": 81
        },
        "WallPlacer.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 81
        },
        "WallPlacer.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 81
        },
        "WallPlacer.Losses.PolicyLoss.mean": {
            "value": 0.12805187948979438,
            "min": 0.11160308079173167,
            "max": 0.23270370190342268,
            "count": 15
        },
        "WallPlacer.Losses.PolicyLoss.sum": {
            "value": 0.12805187948979438,
            "min": 0.11160308079173167,
            "max": 0.23270370190342268,
            "count": 15
        },
        "WallPlacer.Losses.ValueLoss.mean": {
            "value": 101262.415625,
            "min": 40656.07213541667,
            "max": 2096429.225,
            "count": 15
        },
        "WallPlacer.Losses.ValueLoss.sum": {
            "value": 101262.415625,
            "min": 40656.07213541667,
            "max": 2096429.225,
            "count": 15
        },
        "WallPlacer.Policy.LearningRate.mean": {
            "value": 0.00013068005644,
            "min": 0.00013068005644,
            "max": 0.00017310004230000002,
            "count": 15
        },
        "WallPlacer.Policy.LearningRate.sum": {
            "value": 0.00013068005644,
            "min": 0.00013068005644,
            "max": 0.00017310004230000002,
            "count": 15
        },
        "WallPlacer.Policy.Epsilon.mean": {
            "value": 0.14355999999999997,
            "min": 0.14355999999999997,
            "max": 0.15770000000000003,
            "count": 15
        },
        "WallPlacer.Policy.Epsilon.sum": {
            "value": 0.14355999999999997,
            "min": 0.14355999999999997,
            "max": 0.15770000000000003,
            "count": 15
        },
        "WallPlacer.Policy.Beta.mean": {
            "value": 0.0021836439999999993,
            "min": 0.0021836439999999993,
            "max": 0.00288923,
            "count": 15
        },
        "WallPlacer.Policy.Beta.sum": {
            "value": 0.0021836439999999993,
            "min": 0.0021836439999999993,
            "max": 0.00288923,
            "count": 15
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1716313356",
        "python_version": "3.7.16 (default, Jan 17 2023, 16:06:28) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\elect\\.conda\\envs\\ml-agents-2020\\Scripts\\mlagents-learn config\\WallPlacerConfig.yaml --env=Builds\\TrainingBuildBidirectional\\CrowdSim --num-envs=5 --resume",
        "mlagents_version": "0.29.0",
        "mlagents_envs_version": "0.29.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.13.1+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1716318696"
    },
    "total": 5339.4679872,
    "count": 1,
    "self": 5.430527799999254,
    "children": {
        "run_training.setup": {
            "total": 0.5305991999999997,
            "count": 1,
            "self": 0.5305991999999997
        },
        "TrainerController.start_learning": {
            "total": 5333.5068602,
            "count": 1,
            "self": 0.11892490000627731,
            "children": {
                "TrainerController._reset_env": {
                    "total": 6.4724953,
                    "count": 1,
                    "self": 6.4724953
                },
                "TrainerController.advance": {
                    "total": 5326.7258253999935,
                    "count": 1627,
                    "self": 0.11753749999297725,
                    "children": {
                        "env_step": {
                            "total": 5287.93350279999,
                            "count": 1627,
                            "self": 5273.118638799996,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 14.747680099999341,
                                    "count": 1632,
                                    "self": 0.2830679000152436,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 14.464612199984098,
                                            "count": 1632,
                                            "self": 1.6025205999848158,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 12.862091599999282,
                                                    "count": 1632,
                                                    "self": 12.862091599999282
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.06718389999466012,
                                    "count": 1626,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 26576.808484100024,
                                            "count": 1627,
                                            "is_parallel": true,
                                            "self": 59.934787600050186,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.004200200000000542,
                                                    "count": 5,
                                                    "is_parallel": true,
                                                    "self": 0.002461199999999941,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0017390000000006012,
                                                            "count": 10,
                                                            "is_parallel": true,
                                                            "self": 0.0017390000000006012
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 26516.869496299973,
                                                    "count": 1627,
                                                    "is_parallel": true,
                                                    "self": 0.3083933999732835,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 0.2818753000041143,
                                                            "count": 1627,
                                                            "is_parallel": true,
                                                            "self": 0.2818753000041143
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 26515.00808549999,
                                                            "count": 1627,
                                                            "is_parallel": true,
                                                            "self": 26515.00808549999
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 1.2711421000062018,
                                                            "count": 1627,
                                                            "is_parallel": true,
                                                            "self": 0.7971973000084915,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.4739447999977102,
                                                                    "count": 3254,
                                                                    "is_parallel": true,
                                                                    "self": 0.4739447999977102
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 38.674785100011164,
                            "count": 1626,
                            "self": 0.13272840001357622,
                            "children": {
                                "process_trajectory": {
                                    "total": 18.932237399997167,
                                    "count": 1626,
                                    "self": 18.509092999996984,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.42314440000018294,
                                            "count": 1,
                                            "self": 0.42314440000018294
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 19.609819300000424,
                                    "count": 16,
                                    "self": 0.7433506000022589,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 18.866468699998165,
                                            "count": 240,
                                            "self": 18.866468699998165
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.2999996619764715e-06,
                    "count": 1,
                    "self": 3.2999996619764715e-06
                },
                "TrainerController._save_models": {
                    "total": 0.1896113000002515,
                    "count": 1,
                    "self": 0.015406300000904594,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.1742049999993469,
                            "count": 1,
                            "self": 0.1742049999993469
                        }
                    }
                }
            }
        }
    }
}